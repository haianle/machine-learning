
```{r}
library(tidyverse)
library(dslabs)
library(dplyr)
library(caret)
library(ggplot2)
library(HistData)

```
```{r}
library(dslabs)
data("heights")
y <- heights$height

set.seed(2,sample.kind = "Rounding") #if you are using R 3.6 or later

test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
train_set <- heights %>% slice(-test_index)
test_set <- heights %>% slice(test_index)
lm_fit <- mutate(train_set, y = as.numeric(sex == "Female")) %>% lm(y ~height, data = .)

heights %>%
  mutate(x = round(height)) %>%
  group_by(x) %>%
  filter(n()>=10) %>%
  summarize(prop = mean(sex =="Female")) %>%
  ggplot(aes(x,prop)) + geom_point() +
  geom_abline(intercept = lm_fit$coef[1], slope = lm_fit$coef[2])

range(p_hat)

```
```{r}
# fit logistic regression model
glm_fit <- train_set %>%
  mutate(y = as.numeric(sex == "Female")) %>%
  glm(y ~ height,data = ., family = "binomial") 
 p_hat_logic <- predict(glm_fit, newdata = test_set, type = "response")

 tmp <- heights %>% 
   mutate(x =round(height)) %>%
   group_by(x) %>%
   filter(n()> 10) %>%
   summarize (prop =mean(sex == "Female"))
 
 logistic_curve <- data.frame(x = seq(min(tmp$x),max(tmp$x))) %>%
   mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
 
 tmp %>% ggplot(aes(x,prop)) +
   geom_point() +
   geom_line(data = logistic_curve, mapping = aes(x,p_hat),lty =2)
 
 y_hat_logic <- ifelse(p_hat_logic > 0.5, "Female", "Male") %>% factor()
 confusionMatrix(y_hat_logic, test_set$sex)
```

